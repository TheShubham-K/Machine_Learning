{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Sampled Dataset\n",
    "\n",
    "**Learning Objectives**\n",
    "- Sample the natality dataset to create train/eval/test sets\n",
    "- Preprocess the data in Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we'll read data from BigQuery into our notebook to preprocess the data within a Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"cloud-training-demos\"  # Replace with your PROJECT\n",
    "BUCKET = \"cloud-training-bucket\"  # Replace with your BUCKET\n",
    "REGION = \"us-central1\"            # Choose an available region for Cloud MLE\n",
    "TFVERSION = \"1.13\"                # TF version for CMLE to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ML datasets by sampling using BigQuery\n",
    "\n",
    "We'll begin by sampling the BigQuery data to create smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQL query using natality data after the year 2000\n",
    "query_string = \"\"\"\n",
    "WITH\n",
    "  CTE_hash_cols_fixed AS (\n",
    "  SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    year,\n",
    "    month,\n",
    "    CASE\n",
    "      WHEN day IS NULL AND wday IS NULL THEN 0\n",
    "    ELSE\n",
    "    CASE\n",
    "      WHEN day IS NULL THEN wday\n",
    "    ELSE\n",
    "    wday\n",
    "  END\n",
    "  END\n",
    "    AS date,\n",
    "    IFNULL(state,\n",
    "      \"Unknown\") AS state,\n",
    "    IFNULL(mother_birth_state,\n",
    "      \"Unknown\") AS mother_birth_state\n",
    "  FROM\n",
    "    publicdata.samples.natality\n",
    "  WHERE\n",
    "    year > 2000)\n",
    "\n",
    "SELECT\n",
    "  weight_pounds,\n",
    "  is_male,\n",
    "  mother_age,\n",
    "  plurality,\n",
    "  gestation_weeks,\n",
    "  ABS(FARM_FINGERPRINT(CONCAT(CAST(year AS STRING), CAST(month AS STRING), CAST(date AS STRING), CAST(state AS STRING), CAST(mother_birth_state AS STRING)))) AS hashvalues\n",
    "FROM\n",
    "  CTE_hash_cols_fixed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only a limited number of years, months, days, and states in the dataset. Let's see what the hash values are.\n",
    "\n",
    "We'll call BigQuery but group by the hashcolumn and see the number of records for each group. This will enable us to get the correct train/eval/test percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 658107 unique hashvalues.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashvalues</th>\n",
       "      <th>num_babies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1557970813427928760</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8183651910314772965</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3499106308324393870</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588280865661544184</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6927803069586192700</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hashvalues  num_babies\n",
       "0  1557970813427928760         380\n",
       "1  8183651910314772965         857\n",
       "2  3499106308324393870         236\n",
       "3   588280865661544184         282\n",
       "4  6927803069586192700          55"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "bq = bigquery.Client(project = PROJECT)\n",
    "\n",
    "df = bq.query(\"SELECT hashvalues, COUNT(weight_pounds) AS num_babies FROM (\" \n",
    "              + query_string + \n",
    "              \") GROUP BY hashvalues\").to_dataframe()\n",
    "\n",
    "print(\"There are {} unique hashvalues.\".format(len(df)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a query to check if our bucketing values result in the correct sizes of each of our dataset splits and then adjust accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>26080035</td>\n",
       "      <td>0.783845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "      <td>3639721</td>\n",
       "      <td>0.109393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>3552158</td>\n",
       "      <td>0.106761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id dataset_name  num_records  percent_records\n",
       "0           0        train     26080035         0.783845\n",
       "1           1         eval      3639721         0.109393\n",
       "2           2         test      3552158         0.106761"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_percentages_query = \"\"\"\n",
    "WITH\n",
    "  -- Get label, features, and column that we are going to use to split into buckets on\n",
    "  CTE_hash_cols_fixed AS (\n",
    "  SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    year,\n",
    "    month,\n",
    "    CASE\n",
    "      WHEN day IS NULL AND wday IS NULL THEN 0\n",
    "    ELSE\n",
    "    CASE\n",
    "      WHEN day IS NULL THEN wday\n",
    "    ELSE\n",
    "    wday\n",
    "  END\n",
    "  END\n",
    "    AS date,\n",
    "    IFNULL(state,\n",
    "      \"Unknown\") AS state,\n",
    "    IFNULL(mother_birth_state,\n",
    "      \"Unknown\") AS mother_birth_state\n",
    "  FROM\n",
    "    publicdata.samples.natality\n",
    "  WHERE\n",
    "    year > 2000),\n",
    "  CTE_data AS (\n",
    "  SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    ABS(FARM_FINGERPRINT(CONCAT(CAST(year AS STRING), CAST(month AS STRING), CAST(date AS STRING), CAST(state AS STRING), CAST(mother_birth_state AS STRING)))) AS hashvalues\n",
    "  FROM\n",
    "    CTE_hash_cols_fixed),\n",
    "  -- Get the counts of each of the unique hashs of our splitting column\n",
    "  CTE_first_bucketing AS (\n",
    "  SELECT\n",
    "    hashvalues,\n",
    "    COUNT(*) AS num_records\n",
    "  FROM\n",
    "    CTE_data\n",
    "  GROUP BY\n",
    "    hashvalues ),\n",
    "  -- Get the number of records in each of the hash buckets\n",
    "  CTE_second_bucketing AS (\n",
    "  SELECT\n",
    "    MOD(hashvalues, {0}) AS bucket_index,\n",
    "    SUM(num_records) AS num_records\n",
    "  FROM\n",
    "    CTE_first_bucketing\n",
    "  GROUP BY\n",
    "    MOD(hashvalues, {0})),\n",
    "  -- Calculate the overall percentages\n",
    "  CTE_percentages AS (\n",
    "  SELECT\n",
    "    bucket_index,\n",
    "    num_records,\n",
    "    CAST(num_records AS FLOAT64) / (\n",
    "    SELECT\n",
    "      SUM(num_records)\n",
    "    FROM\n",
    "      CTE_second_bucketing) AS percent_records\n",
    "  FROM\n",
    "    CTE_second_bucketing ),\n",
    "  -- Choose which of the hash buckets will be used for training and pull in their statistics\n",
    "  CTE_train AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    \"train\" AS dataset_name\n",
    "  FROM\n",
    "    CTE_percentages\n",
    "  WHERE\n",
    "    bucket_index >= 0\n",
    "    AND bucket_index < {1}),\n",
    "  -- Choose which of the hash buckets will be used for validation and pull in their statistics\n",
    "  CTE_eval AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    \"eval\" AS dataset_name\n",
    "  FROM\n",
    "    CTE_percentages\n",
    "  WHERE\n",
    "    bucket_index >= {1}\n",
    "    AND bucket_index < {2}),\n",
    "  -- Choose which of the hash buckets will be used for testing and pull in their statistics\n",
    "  CTE_test AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    \"test\" AS dataset_name\n",
    "  FROM\n",
    "    CTE_percentages\n",
    "  WHERE\n",
    "    bucket_index >= {2}\n",
    "    AND bucket_index < {0}),\n",
    "  -- Union the training, validation, and testing dataset statistics\n",
    "  CTE_union AS (\n",
    "  SELECT\n",
    "    0 AS dataset_id,\n",
    "    *\n",
    "  FROM\n",
    "    CTE_train\n",
    "  UNION ALL\n",
    "  SELECT\n",
    "    1 AS dataset_id,\n",
    "    *\n",
    "  FROM\n",
    "    CTE_eval\n",
    "  UNION ALL\n",
    "  SELECT\n",
    "    2 AS dataset_id,\n",
    "    *\n",
    "  FROM\n",
    "    CTE_test ),\n",
    "  -- Show final splitting and associated statistics\n",
    "  CTE_split AS (\n",
    "  SELECT\n",
    "    dataset_id,\n",
    "    dataset_name,\n",
    "    SUM(num_records) AS num_records,\n",
    "    SUM(percent_records) AS percent_records\n",
    "  FROM\n",
    "    CTE_union\n",
    "  GROUP BY\n",
    "    dataset_id,\n",
    "    dataset_name )\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  CTE_split\n",
    "ORDER BY\n",
    "    dataset_id\n",
    "\"\"\"\n",
    "\n",
    "modulo_divisor = 100\n",
    "train_percent = 80.0\n",
    "eval_percent = 10.0\n",
    "\n",
    "train_buckets = int(modulo_divisor * train_percent / 100.0)\n",
    "eval_buckets = int(modulo_divisor * eval_percent / 100.0)\n",
    "\n",
    "df = bq.query(sampling_percentages_query.format(modulo_divisor, train_buckets, train_buckets + eval_buckets)).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a way to get a well-distributed portion of the data in such a way that the train/eval/test sets do not overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18998 examples in the train dataset.\n",
      "There are 1513 examples in the validation dataset.\n",
      "There are 1389 examples in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "# Added every_n so that we can now subsample from each of the hash values to get approximately the record counts we want\n",
    "every_n = 500\n",
    "\n",
    "train_query = \"SELECT * FROM ({0}) WHERE MOD(hashvalues, {1} * 100) < 80\".format(query_string, every_n)\n",
    "eval_query = \"SELECT * FROM ({0}) WHERE MOD(hashvalues, {1} * 100) >= 80 AND MOD(hashvalues, {1} * 100) < 90\".format(query_string, every_n)\n",
    "test_query = \"SELECT * FROM ({0}) WHERE MOD(hashvalues, {1} * 100) >= 90 AND MOD(hashvalues, {1} * 100) < 100\".format(query_string, every_n)\n",
    "\n",
    "train_df = bq.query(train_query).to_dataframe()\n",
    "eval_df = bq.query(eval_query).to_dataframe()\n",
    "test_df = bq.query(test_query).to_dataframe()\n",
    "\n",
    "print(\"There are {} examples in the train dataset.\".format(len(train_df)))\n",
    "print(\"There are {} examples in the validation dataset.\".format(len(eval_df)))\n",
    "print(\"There are {} examples in the test dataset.\".format(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data using Pandas\n",
    "\n",
    "We'll perform a few preprocessing steps to the data in our dataset. Let's add extra rows to simulate the lack of ultrasound. That is we'll duplicate some rows and make the `is_male` field be `Unknown`. Also, if there is more than child we'll change the `plurality` to `Multiple(2+)`. While we're at it, We'll also change the plurality column to be a string. We'll perform these operations below. \n",
    "\n",
    "Let's start by examining the training dataset as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hashvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.483388</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6380000856187650041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.812284</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7823092823372300071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.234265</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1861629504184950069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.275255</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5734139609924950008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.640731</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3838362205187550017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       8.483388     True          42          1             39.0   \n",
       "1       6.812284     True          44          2             36.0   \n",
       "2       8.234265     True          42          1             38.0   \n",
       "3       7.275255     True          42          1             38.0   \n",
       "4       4.640731    False          51          2             40.0   \n",
       "\n",
       "            hashvalues  \n",
       "0  6380000856187650041  \n",
       "1  7823092823372300071  \n",
       "2  1861629504184950069  \n",
       "3  5734139609924950008  \n",
       "4  3838362205187550017  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, notice that there are some very important numeric fields that are missing in some rows (the count in Pandas doesn't count missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hashvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18998.000000</td>\n",
       "      <td>18998.000000</td>\n",
       "      <td>18850.000000</td>\n",
       "      <td>1.899800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.243111</td>\n",
       "      <td>27.782346</td>\n",
       "      <td>1.038162</td>\n",
       "      <td>38.639735</td>\n",
       "      <td>4.288488e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.337393</td>\n",
       "      <td>6.195585</td>\n",
       "      <td>0.210196</td>\n",
       "      <td>2.594170</td>\n",
       "      <td>2.534495e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500449</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.826385e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.572531</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.861630e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.339189</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.835475e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.062305</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.784884e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.500210</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>9.210618e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds    mother_age     plurality  gestation_weeks  \\\n",
       "count   18978.000000  18998.000000  18998.000000     18850.000000   \n",
       "mean        7.243111     27.782346      1.038162        38.639735   \n",
       "std         1.337393      6.195585      0.210196         2.594170   \n",
       "min         0.500449     13.000000      1.000000        17.000000   \n",
       "25%         6.572531     23.000000      1.000000        38.000000   \n",
       "50%         7.339189     28.000000      1.000000        39.000000   \n",
       "75%         8.062305     32.000000      1.000000        40.000000   \n",
       "max        12.500210     51.000000      4.000000        47.000000   \n",
       "\n",
       "         hashvalues  \n",
       "count  1.899800e+04  \n",
       "mean   4.288488e+18  \n",
       "std    2.534495e+18  \n",
       "min    5.826385e+15  \n",
       "25%    1.861630e+18  \n",
       "50%    3.835475e+18  \n",
       "75%    6.784884e+18  \n",
       "max    9.210618e+18  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always crucial to clean raw data before using in machine learning, so we have a preprocessing step. We'll define a `preprocess` function below. Note that the mother's age is an input to our model so users will have to provide the mother's age; otherwise, our service won't work. The features we use for our model were chosen because they are such good predictors and because they are easy enough to collect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess(df):\n",
    "    # Clean up data\n",
    "    # Remove what we don\"t want to use for training\n",
    "    df = df[df.weight_pounds > 0]\n",
    "    df = df[df.mother_age > 0]\n",
    "    df = df[df.gestation_weeks > 0]\n",
    "    df = df[df.plurality > 0]\n",
    "\n",
    "    # Modify plurality field to be a string\n",
    "    twins_etc = dict(zip([1,2,3,4,5],\n",
    "                   [\"Single(1)\", \"Twins(2)\", \"Triplets(3)\", \"Quadruplets(4)\", \"Quintuplets(5)\"]))\n",
    "    df[\"plurality\"].replace(twins_etc, inplace = True)\n",
    "\n",
    "    # Now create extra rows to simulate lack of ultrasound\n",
    "    no_ultrasound = df.copy(deep = True)\n",
    "    no_ultrasound.loc[no_ultrasound[\"plurality\"] != \"Single(1)\", \"plurality\"] = \"Multiple(2+)\"\n",
    "    no_ultrasound[\"is_male\"] = \"Unknown\"\n",
    "\n",
    "    # Concatenate both datasets together and shuffle\n",
    "    return pd.concat([df, no_ultrasound]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the train/eval/test set and see a small sample of the training data after our preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess(train_df)\n",
    "eval_df = preprocess(eval_df)\n",
    "test_df = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hashvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.430070</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>34</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2644101647865250034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.687926</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>701411312121250028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.741329</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1861629504184950069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.875727</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6300252072602950014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.635914</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6784884401981100070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0      10.430070  Unknown          34  Single(1)             40.0   \n",
       "1       5.687926    False          23  Single(1)             38.0   \n",
       "2       8.741329    False          22  Single(1)             41.0   \n",
       "3       3.875727  Unknown          18  Single(1)             36.0   \n",
       "4       6.635914    False          29  Single(1)             38.0   \n",
       "\n",
       "            hashvalues  \n",
       "0  2644101647865250034  \n",
       "1   701411312121250028  \n",
       "2  1861629504184950069  \n",
       "3  6300252072602950014  \n",
       "4  6784884401981100070  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hashvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37671</th>\n",
       "      <td>6.541115</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2177280183356650077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37672</th>\n",
       "      <td>7.881526</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3480083103445950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37673</th>\n",
       "      <td>8.476774</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4614303140002600076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37674</th>\n",
       "      <td>7.125340</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>23</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7524082756449550067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>7.771295</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>31</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3480083103445950001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "37671       6.541115    False          23  Single(1)             38.0   \n",
       "37672       7.881526  Unknown          30  Single(1)             39.0   \n",
       "37673       8.476774  Unknown          20  Single(1)             40.0   \n",
       "37674       7.125340  Unknown          23  Single(1)             40.0   \n",
       "37675       7.771295  Unknown          31  Single(1)             40.0   \n",
       "\n",
       "                hashvalues  \n",
       "37671  2177280183356650077  \n",
       "37672  3480083103445950001  \n",
       "37673  4614303140002600076  \n",
       "37674  7524082756449550067  \n",
       "37675  3480083103445950001  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at a summary of the dataset. Note that we only see numeric columns, so `plurality` does not show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hashvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37676.000000</td>\n",
       "      <td>37676.000000</td>\n",
       "      <td>37676.000000</td>\n",
       "      <td>3.767600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.244695</td>\n",
       "      <td>27.767544</td>\n",
       "      <td>38.644973</td>\n",
       "      <td>4.277547e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.335645</td>\n",
       "      <td>6.189406</td>\n",
       "      <td>2.576290</td>\n",
       "      <td>2.535502e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500449</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.826385e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.580799</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.861630e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.341393</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.825089e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.062305</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.784884e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.500210</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>9.210618e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds    mother_age  gestation_weeks    hashvalues\n",
       "count   37676.000000  37676.000000     37676.000000  3.767600e+04\n",
       "mean        7.244695     27.767544        38.644973  4.277547e+18\n",
       "std         1.335645      6.189406         2.576290  2.535502e+18\n",
       "min         0.500449     13.000000        18.000000  5.826385e+15\n",
       "25%         6.580799     23.000000        38.000000  1.861630e+18\n",
       "50%         7.341393     28.000000        39.000000  3.825089e+18\n",
       "75%         8.062305     32.000000        40.000000  6.784884e+18\n",
       "max        12.500210     51.000000        47.000000  9.210618e+18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to .csv files \n",
    "\n",
    "In the final versions, we want to read from files, not Pandas dataframes. So, we write the Pandas dataframes out as csv files. Using csv files gives us the advantage of shuffling during read. This is important for distributed training because some workers might be slower than others, and shuffling the data helps prevent the same data from being assigned to the slow workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = \"weight_pounds,is_male,mother_age,plurality,gestation_weeks\".split(',')\n",
    "train_df.to_csv(path_or_buf = \"train.csv\", columns = columns, header = False, index = False)\n",
    "eval_df.to_csv(path_or_buf = \"eval.csv\", columns = columns, header = False, index = False)\n",
    "test_df.to_csv(path_or_buf = \"test.csv\", columns = columns, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3000 eval.csv\n",
      "   2764 test.csv\n",
      "  37676 train.csv\n",
      "  43440 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> eval.csv <==\n",
      "6.4374980503999994,False,21,Single(1),37.0\n",
      "10.06189763768,Unknown,23,Single(1),40.0\n",
      "6.686620406459999,False,23,Single(1),40.0\n",
      "7.936641432,False,36,Single(1),38.0\n",
      "7.0437692708999995,Unknown,37,Single(1),39.0\n",
      "7.62578964258,False,31,Single(1),39.0\n",
      "6.1883756943399995,True,25,Single(1),38.0\n",
      "8.3334735036,True,21,Single(1),38.0\n",
      "7.81318256528,True,29,Single(1),38.0\n",
      "8.18796841068,False,20,Single(1),39.0\n",
      "\n",
      "==> test.csv <==\n",
      "8.50102482272,Unknown,35,Single(1),40.0\n",
      "9.4909003791,True,26,Single(1),40.0\n",
      "8.18796841068,Unknown,23,Single(1),37.0\n",
      "7.87491199864,Unknown,39,Single(1),38.0\n",
      "7.3083239852999995,True,30,Single(1),38.0\n",
      "7.17825125072,Unknown,29,Single(1),38.0\n",
      "6.1244416383599996,False,22,Single(1),38.0\n",
      "6.6579603124,True,23,Single(1),39.0\n",
      "8.000575487979999,Unknown,40,Single(1),38.0\n",
      "6.77480531126,Unknown,21,Single(1),39.0\n",
      "\n",
      "==> train.csv <==\n",
      "10.430069615219999,Unknown,34,Single(1),40.0\n",
      "5.6879263596,False,23,Single(1),38.0\n",
      "8.7413286883,False,22,Single(1),41.0\n",
      "3.87572656596,Unknown,18,Single(1),36.0\n",
      "6.6359140862,False,29,Single(1),38.0\n",
      "4.49963476742,Unknown,28,Single(1),36.0\n",
      "8.75014717878,False,29,Single(1),41.0\n",
      "7.25100379718,True,31,Single(1),38.0\n",
      "6.6248909731,True,25,Single(1),38.0\n",
      "7.1760466281,True,19,Single(1),40.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> eval.csv <==\n",
      "7.31273323054,Unknown,21,Single(1),43.0\n",
      "7.7492485093,False,31,Single(1),47.0\n",
      "9.43798943622,False,25,Single(1),39.0\n",
      "6.1244416383599996,False,29,Single(1),40.0\n",
      "12.125424409999999,True,21,Single(1),39.0\n",
      "8.0138032237,Unknown,21,Single(1),41.0\n",
      "8.62448368944,False,20,Single(1),39.0\n",
      "8.56275425608,Unknown,35,Single(1),39.0\n",
      "7.7933409617,Unknown,36,Single(1),41.0\n",
      "1.5542589471,Unknown,31,Single(1),26.0\n",
      "\n",
      "==> test.csv <==\n",
      "7.25100379718,Unknown,16,Single(1),41.0\n",
      "9.12493302418,True,23,Single(1),41.0\n",
      "8.375361333379999,False,39,Single(1),39.0\n",
      "6.8122838958,Unknown,40,Single(1),39.0\n",
      "6.4815905028,True,21,Single(1),37.0\n",
      "7.43839671988,Unknown,26,Single(1),39.0\n",
      "7.6279942652,True,32,Single(1),39.0\n",
      "8.313631900019999,Unknown,43,Single(1),39.0\n",
      "6.9996768185,Unknown,22,Single(1),37.0\n",
      "8.27615331548,Unknown,35,Single(1),41.0\n",
      "\n",
      "==> train.csv <==\n",
      "8.9948602896,Unknown,37,Single(1),43.0\n",
      "8.93754010148,True,25,Single(1),40.0\n",
      "3.12615487516,Unknown,34,Multiple(2+),38.0\n",
      "6.93794738514,Unknown,33,Single(1),38.0\n",
      "5.5005334369,True,31,Single(1),34.0\n",
      "6.54111531354,False,23,Single(1),38.0\n",
      "7.8815258665,Unknown,30,Single(1),39.0\n",
      "8.4767739739,Unknown,20,Single(1),40.0\n",
      "7.12534030784,Unknown,23,Single(1),40.0\n",
      "7.7712947355,Unknown,31,Single(1),40.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tail *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017-2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
